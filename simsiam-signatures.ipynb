{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d349c9af-42a8-443d-afaf-54394c6523cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "import simsiam.loader\n",
    "import simsiam.builder\n",
    "import simsiam.resnet18\n",
    "import simsiam.resnet18_signatures\n",
    "import simsiam.builder_resnet18\n",
    "import simsiam.builder_resnet18_2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90835eb1-029c-4760-8cba-d51f9f9e34fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "files_org = listdir(\"signatures/org/train\")\n",
    "files_forg = listdir(\"signatures/forg/train\")\n",
    "files = ['signatures/org/train/' + s for s in files_org if s[0] != '.'] + ['signatures/forg/train/' + s for s in files_forg if s[0] != '.']\n",
    "images = []\n",
    "\n",
    "\n",
    "for name in files:\n",
    "    im = Image.open(name)\n",
    "    im = im.convert(\"L\")\n",
    "    im = im.convert(\"RGB\")\n",
    "    images.append(im)\n",
    "\n",
    "rez = transforms.Resize((32, 32))\n",
    "tens = transforms.ToTensor()\n",
    "tensors = tens(rez(images[0]))\n",
    "tensors = tensors[None, :,]\n",
    "\n",
    "for i in range(1, len(images)):\n",
    "    temp = tens(rez(images[i]))\n",
    "    temp = temp[None, :,]\n",
    "    tensors = torch.cat((tensors, temp))\n",
    "print(tensors.size())\n",
    "\n",
    "m1 = torch.mean(tensors)\n",
    "print(m1)\n",
    "(std, mean) = torch.std_mean(tensors)\n",
    "print(std)\n",
    "print(mean)\n",
    "\n",
    "#32x32\n",
    "#mean 0.9495\n",
    "#std 0.0535\n",
    "\n",
    "#256x256\n",
    "#mean 0.9495\n",
    "#std 0.0822"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01391662-6905-49a6-b9a2-f79f1a912970",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation = [\n",
    "    transforms.ToTensor(),\n",
    "    ThresholdTransform(),\n",
    "    transforms.Resize((32, 32)),\n",
    "    #transforms.CenterCrop(28)\n",
    "    #ThresholdTransform(),\n",
    "    \n",
    "]\n",
    "\n",
    "im = Image.open(\"signatures/org/train/original_1_2.png\")\n",
    "im = im.convert(\"L\")\n",
    "im = im.convert(\"RGB\")\n",
    "temp=transforms.Compose(augmentation)\n",
    "nim = temp(im)\n",
    "plt.figure(1)\n",
    "plt.imshow(  nim.permute(1, 2, 0)  )\n",
    "\n",
    "im = Image.open(\"signatures/forg/train/forgeries_1_19.png\")\n",
    "im = im.convert(\"L\")\n",
    "im = im.convert(\"RGB\")\n",
    "temp=transforms.Compose(augmentation)\n",
    "nim = temp(im)\n",
    "plt.figure(2)\n",
    "plt.imshow(  nim.permute(1, 2, 0)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94b06dd-01de-433e-ab2a-21a20dbc719c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignatureDataset():\n",
    "    def __init__(self, images, transform):\n",
    "        # used to prepare the labels and images path\n",
    "        self.images = images\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        image = self.images[index]\n",
    "        image = self.transform(image)\n",
    "\n",
    "        return image\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "class ThresholdTransform(object):\n",
    "    def __init__(self):\n",
    "        self.thr = 0.85\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return (x > self.thr).to(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45285d5b-c7d5-4d72-b5f3-1f70ac419e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = simsiam.resnet18.resnet18()\n",
    "for child in model.children():\n",
    "    for layer in child.modules():\n",
    "        print(layer)\n",
    "model = simsiam.builder_resnet18_2.SimSiam(\n",
    "        model, 2048, 512)\n",
    "\n",
    "lr = 0.03\n",
    "# batch_size = 512, workers = 32\n",
    "batch_size = 256\n",
    "workers = 6\n",
    "momentum = 0.9\n",
    "weight_decay = 0.0005\n",
    "start_epoch = 0\n",
    "epochs = 100\n",
    "\n",
    "init_lr = lr * batch_size / 256\n",
    "criterion = nn.CosineSimilarity(dim=1)\n",
    "\n",
    "optim_params = [{'params': model.encoder.parameters(), 'fix_lr': False},\n",
    "                        {'params': model.predictor.parameters(), 'fix_lr': True}]\n",
    "\n",
    "optimizer = torch.optim.SGD(optim_params, init_lr,\n",
    "                                momentum=momentum,\n",
    "                                weight_decay=weight_decay)\n",
    "\n",
    "\n",
    "data_storage = \"./data\"\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                                     std=[1, 1, 1])\n",
    "\n",
    "augmentation = [\n",
    "    transforms.ToTensor(),\n",
    "    ThresholdTransform(),\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.RandomResizedCrop(28, scale=(0.2, 1.)),\n",
    "    transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    #transforms.RandomApply([simsiam.loader.GaussianBlur([.1, 2.])], p=0.5),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    normalize\n",
    "    ]\n",
    "\n",
    "dataset = SignatureDataset(images, transform=simsiam.loader.TwoCropsTransform(transforms.Compose(augmentation)))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, shuffle= True,\n",
    "        num_workers=workers, pin_memory=True, drop_last=True)\n",
    "\n",
    "device = torch.device('cuda') \n",
    "print(device)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30032e40-767d-47e5-a3bf-fab85aded2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, gpu = None):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "    \n",
    "    # switch to train mode\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    for i, images in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        if gpu is not None:\n",
    "            images[0] = images[0].cuda(args.gpu, non_blocking=True)\n",
    "            images[1] = images[1].cuda(args.gpu, non_blocking=True)\n",
    "        \n",
    "        images[0], images[1] = images[0].to(device), images[1].to(device)\n",
    "        # compute output and loss\n",
    "     \n",
    "        p1, p2, z1, z2 = model(x1=images[0], x2=images[1])\n",
    "        loss = -(criterion(p1, z2).mean() + criterion(p2, z1).mean()) * 0.5\n",
    "\n",
    "        losses.update(loss.item(), images[0].size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            progress.display(i)\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, init_lr, epoch, epochs):\n",
    "    \"\"\"Decay the learning rate based on schedule\"\"\"\n",
    "    cur_lr = init_lr * 0.5 * (1. + math.cos(math.pi * epoch / epochs))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        if 'fix_lr' in param_group and param_group['fix_lr']:\n",
    "            param_group['lr'] = init_lr\n",
    "        else:\n",
    "            param_group['lr'] = cur_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cbb8d0-d4f2-4924-a307-4b74375da092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trained 100 epochs\n",
    "#model.load_state_dict(torch.load('nets/simsiam_resnet18_v2.pt'))\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    \n",
    "    adjust_learning_rate(optimizer, init_lr, epoch, epochs)\n",
    "    train(train_loader, model, criterion, optimizer, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9977a95c-6448-49da-ae50-4490d379bd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'nets/simsiam_signatures_100.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f774df-7432-4e52-b8c9-8c5460333b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = [0]*2560\n",
    "for i, images in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        \n",
    "        images[0], images[1] = images[0], images[1]\n",
    "        # compute output and loss\n",
    "     \n",
    "        p1, p2, z1, z2 = model(x1=images[0].cuda(), x2=images[1].cuda())\n",
    "        loss = (criterion(p1, z2) + criterion(p2, z1)) * 0.5\n",
    "        res[i*60:i*60-1] = loss.tolist()\n",
    "\n",
    "plt.hist(res, 40, (-1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17984ae2-9b3e-48da-9b87-a8c50427d072",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trained on signatures\n",
    "model = simsiam.resnet18.resnet18()\n",
    "\n",
    "model = simsiam.builder_resnet18_2.SimSiam(\n",
    "        model, 2048, 512)\n",
    "model.load_state_dict(torch.load('nets/simsiam_signatures_100.pt'))\n",
    "model.eval()\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                                     std=[1, 1, 1])\n",
    "augmentation = [\n",
    "    transforms.ToTensor(),\n",
    "    ThresholdTransform(),\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.CenterCrop(28),\n",
    "    normalize\n",
    "]\n",
    "cos = nn.CosineSimilarity(dim=0)\n",
    "files_org = listdir(\"signatures/org/val\")\n",
    "files_forg = listdir(\"signatures/forg/val\")\n",
    "files_org.sort()\n",
    "files_forg.sort()\n",
    "images_org = []\n",
    "images_forg = []\n",
    "\n",
    "for name in files_org:\n",
    "    if name[0] != '.':\n",
    "        im = Image.open(\"signatures/org/val/\" + name)\n",
    "        im = im.convert(\"L\")\n",
    "        im = im.convert(\"RGB\")\n",
    "        images_org.append(im)\n",
    "    \n",
    "for name in files_forg:\n",
    "    if name[0] != '.':\n",
    "        im = Image.open(\"signatures/forg/val/\" + name)\n",
    "        im = im.convert(\"L\")\n",
    "        im = im.convert(\"RGB\")\n",
    "        images_forg.append(im)\n",
    "\n",
    "dataset_org = SignatureDataset(images_org, transform=transforms.Compose(augmentation))\n",
    "\n",
    "train_loader_org = torch.utils.data.DataLoader(dataset_org, batch_size = 24, shuffle= False,\n",
    "        num_workers=4, pin_memory=True, drop_last=True)    \n",
    "    \n",
    "dataset_forg = SignatureDataset(images_forg, transform=transforms.Compose(augmentation))\n",
    "\n",
    "train_loader_forg = torch.utils.data.DataLoader(dataset_forg, batch_size = 24, shuffle= False,\n",
    "        num_workers=4, pin_memory=True, drop_last=True)\n",
    "\n",
    "best_threshold = -1\n",
    "best_acc = -1\n",
    "for itera in range(0, 100):\n",
    "    count_org = 0\n",
    "    sum_org = 0\n",
    "    threshold = itera/100\n",
    "    corr_org = 0\n",
    "    corr_forg = 0\n",
    "\n",
    "    sl1 = [0] * 1380\n",
    "    for x, images in enumerate(train_loader_org):\n",
    "        res1 = model.forward_lat(images).detach()\n",
    "        for i in range(0, 24):\n",
    "            for j in range(0, 24):\n",
    "                if j > i:\n",
    "                    count_org+=1\n",
    "                    diff = cos(res1[i],res1[j])\n",
    "                    sum_org+= diff\n",
    "                    sl1[count_org-1] = diff.item()\n",
    "                    if(diff.item() >= threshold):\n",
    "                        corr_org += 1\n",
    "\n",
    "    it_org = iter(train_loader_org)\n",
    "    it_forg = iter(train_loader_forg)\n",
    "    count_forg = 0\n",
    "    sum_forg = 0\n",
    "    sl2 = [0] * 2880\n",
    "    for x in range(0, 5):\n",
    "        images_org = next(it_org)\n",
    "        images_forg = next(it_forg)\n",
    "        res1 = model.forward_lat(images_org).detach()\n",
    "        res2 = model.forward_lat(images_forg).detach()\n",
    "        for i in range(0, 24):\n",
    "            for j in range(0, 24):\n",
    "                count_forg+=1\n",
    "                diff = cos(res1[i],res2[j])\n",
    "                sum_forg+= diff\n",
    "                sl2[count_forg-1] = diff.item()\n",
    "                if(diff.item() < threshold):\n",
    "                    corr_forg += 1\n",
    "    acc = (corr_org/count_org+corr_forg/count_forg)/2\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_threshold = threshold\n",
    "print(best_acc)\n",
    "print(best_threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfb9526-a5c6-4f03-812c-d51cf726604d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing on signatures\n",
    "model = simsiam.resnet18.resnet18()\n",
    "\n",
    "model = simsiam.builder_resnet18_2.SimSiam(\n",
    "        model, 2048, 512)\n",
    "model.load_state_dict(torch.load('nets/simsiam_signatures_100.pt'))\n",
    "model.eval()\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                                     std=[1, 1, 1])\n",
    "augmentation = [\n",
    "    transforms.ToTensor(),\n",
    "    ThresholdTransform(),\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.CenterCrop(28),\n",
    "    normalize\n",
    "]\n",
    "cos = nn.CosineSimilarity(dim=0)\n",
    "files_org = listdir(\"signatures/org/test\")\n",
    "files_forg = listdir(\"signatures/forg/test\")\n",
    "files_org.sort()\n",
    "files_forg.sort()\n",
    "images_org = []\n",
    "images_forg = []\n",
    "\n",
    "for name in files_org:\n",
    "    if name[0] != '.':\n",
    "        im = Image.open(\"signatures/org/test/\" + name)\n",
    "        im = im.convert(\"L\")\n",
    "        im = im.convert(\"RGB\")\n",
    "        images_org.append(im)\n",
    "    \n",
    "for name in files_forg:\n",
    "    if name[0] != '.':\n",
    "        im = Image.open(\"signatures/forg/test/\" + name)\n",
    "        im = im.convert(\"L\")\n",
    "        im = im.convert(\"RGB\")\n",
    "        images_forg.append(im)\n",
    "\n",
    "dataset_org = SignatureDataset(images_org, transform=transforms.Compose(augmentation))\n",
    "\n",
    "train_loader_org = torch.utils.data.DataLoader(dataset_org, batch_size = 24, shuffle= False,\n",
    "        num_workers=4, pin_memory=True, drop_last=True)    \n",
    "    \n",
    "dataset_forg = SignatureDataset(images_forg, transform=transforms.Compose(augmentation))\n",
    "\n",
    "train_loader_forg = torch.utils.data.DataLoader(dataset_forg, batch_size = 24, shuffle= False,\n",
    "        num_workers=4, pin_memory=True, drop_last=True)\n",
    "\n",
    "best_threshold = -1\n",
    "best_acc = -1\n",
    "count_org = 0\n",
    "sum_org = 0\n",
    "threshold = 0.47\n",
    "corr_org = 0\n",
    "corr_forg = 0\n",
    "\n",
    "sl1 = [0] * 1380\n",
    "for x, images in enumerate(train_loader_org):\n",
    "    res1 = model.forward_lat(images).detach()\n",
    "    for i in range(0, 24):\n",
    "        for j in range(0, 24):\n",
    "            if j > i:\n",
    "                count_org+=1\n",
    "                diff = cos(res1[i],res1[j])\n",
    "                sum_org+= diff\n",
    "                sl1[count_org-1] = diff.item()\n",
    "                if(diff.item() >= threshold):\n",
    "                    corr_org += 1\n",
    "\n",
    "it_org = iter(train_loader_org)\n",
    "it_forg = iter(train_loader_forg)\n",
    "count_forg = 0\n",
    "sum_forg = 0\n",
    "sl2 = [0] * 2880\n",
    "for x in range(0, 5):\n",
    "    images_org = next(it_org)\n",
    "    images_forg = next(it_forg)\n",
    "    res1 = model.forward_lat(images_org).detach()\n",
    "    res2 = model.forward_lat(images_forg).detach()\n",
    "    for i in range(0, 24):\n",
    "        for j in range(0, 24):\n",
    "            count_forg+=1\n",
    "            diff = cos(res1[i],res2[j])\n",
    "            sum_forg+= diff\n",
    "            sl2[count_forg-1] = diff.item()\n",
    "            if(diff.item() < threshold):\n",
    "                corr_forg += 1\n",
    "\n",
    "print(corr_org/count_org)\n",
    "print(corr_forg/count_forg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92da092-0e81-4c12-8b31-8c795b0b9bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "f.set_size_inches(18.5/1.5, 10.5/1.5)\n",
    "ax1.hist(sl1, 80, (-1, 1))\n",
    "ax1.set_title('Distribution of similarity for positive pairs')\n",
    "ax1.set_ylim([0, 450])\n",
    "ax2.hist(sl2, 80, (-1, 1))\n",
    "ax2.set_title('Distribution of similarity for negative pairs')\n",
    "ax2.set_ylim([0, 940])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccf7738-7dea-4d2d-a323-7abf65cff3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.hist(sl1, 40, (0, 1))\n",
    "plt.show()\n",
    "plt.figure(2)\n",
    "plt.hist(sl2, 40, (0, 1))\n",
    "plt.show()\n",
    "print(sum(sl1)/len(sl1))\n",
    "print(sum(sl2)/len(sl2))"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-9.m82",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m82"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
