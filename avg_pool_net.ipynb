{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f31cbcf-2b7e-47aa-ac2c-0987663b7da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "import simsiam.loader\n",
    "import simsiam.builder\n",
    "import simsiam.builder_resnet18_2\n",
    "import simsiam.resnet18\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #self.lin1 = nn.Linear(512,50)\n",
    "        self.lin2 = nn.Linear(512,10)\n",
    "        #self.lin3 = nn.Linear(20,10)\n",
    "        #self.lin4 = nn.Linear(20,10)\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "                \n",
    "    def forward(self, x):\n",
    "        #x = F.relu(self.lin1(x))\n",
    "        #x = F.relu(self.lin2(x))\n",
    "        #x = F.relu(self.lin3(x))\n",
    "        x = self.lin2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cea820d9-9510-45ff-8a69-2f3ac3e10627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781\n"
     ]
    }
   ],
   "source": [
    "model_names = sorted(name for name in models.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "    and callable(models.__dict__[name]))\n",
    "device = torch.device('cuda') \n",
    "model = simsiam.builder_resnet18_2.SimSiam(\n",
    "        simsiam.resnet18.resnet18(), 2048, 512)\n",
    "\n",
    "#model.load_state_dict(torch.load('nets/simsiam_resnet18_assym.pt'))\n",
    "model = torch.load(\"fixlr100.pt\")\n",
    "\n",
    "images = torch.load('data_sup/X_250.pt')\n",
    "labels = torch.load('data_sup/y_250.pt')\n",
    "\n",
    "im = []\n",
    "lab = []\n",
    "\n",
    "model.to(device)\n",
    "\"\"\"\n",
    "for i in range(int(len(images)/4)):\n",
    "    input_ = torch.cat((images[i].cuda(), images[i+1].cuda(), images[i+2].cuda(), images[i+3].cuda()), 0)\n",
    "    im.append(model.forward_lat_pool(input_).detach())\n",
    "    lab.append(torch.cat((labels[i].cuda(), labels[i+1].cuda(), labels[i+2].cuda(), labels[i+3].cuda()), 0))\n",
    "    #input_ = torch.cat((images[i], images[i+1], images[i+2], images[i+3]), 0)\n",
    "    #im.append(model.forward_lat_pool(input_).detach())\n",
    "    #lab.append(torch.cat((labels[i], labels[i+1], labels[i+2], labels[i+3]), 0))\n",
    "   \"\"\" \n",
    "normalize = transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                                     std=[0.2023, 0.1994, 0.2010])\n",
    "augmentation = [\n",
    "    #transforms.RandomResizedCrop(28, scale=(0.2, 1.)),\n",
    "    #transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n",
    "    #transforms.RandomGrayscale(p=0.2),\n",
    "    #transforms.RandomApply([simsiam.loader.GaussianBlur([.1, 2.])], p=0.5),\n",
    "    #transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "    ]\n",
    "data_storage = \"./data\"\n",
    "trainset = torchvision.datasets.CIFAR10(root=data_storage, train=True,\n",
    "                                        download=True, transform=simsiam.loader.TwoCropsTransform(transforms.Compose(augmentation)))\n",
    "\n",
    "    \n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size = 64, shuffle= True,\n",
    "        num_workers=4, pin_memory=True, drop_last=True)\n",
    "\n",
    "\n",
    "im1 = []\n",
    "lab1 = []\n",
    "\n",
    "for images1, labels1 in train_loader:\n",
    "    input_ = images1[0].cuda()\n",
    "    im1.append(model.forward_lat_pool(input_).detach())\n",
    "    lab1.append(labels1.cuda())\n",
    "    #print(input_.shape)\n",
    "    \n",
    "print(len(im1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4937d43-c953-43f6-9723-1ccac307548d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "[1,   781] loss: 0.717\n",
      "[11,   781] loss: 0.298\n",
      "[21,   781] loss: 0.272\n",
      "[31,   781] loss: 0.261\n",
      "[41,   781] loss: 0.254\n",
      "[51,   781] loss: 0.250\n",
      "[61,   781] loss: 0.247\n",
      "[71,   781] loss: 0.244\n",
      "[81,   781] loss: 0.242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6451\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# NOTERA ATT Net() mÃ¥ste ha samma input dim som model har output dim. \n",
    "class SimSiamNet:\n",
    "    def __init__(self, model1, model2):\n",
    "        super().__init__()\n",
    "        self.simsiam = model1\n",
    "        self.classifier = model2\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.simsiam.forward_lat_pool(x).detach()\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.CenterCrop(28),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "def val_acc(simsiam_net):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        times = 0\n",
    "        for data in testloader:\n",
    "            times += 1\n",
    "            images, labels = data\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = simsiam_net.forward(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "    return correct / total\n",
    "\n",
    "net = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.02, weight_decay=0, momentum=0.9)\n",
    "\n",
    "val_acc_lst = []\n",
    "net.to(device)\n",
    "for epoch in range(90):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i in range(len(im1)):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = im1[i], lab1[i]\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        #print(f\"Pred: {outputs[0].argmax()}, Label: {labels[0]}\")\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    #if epoch % 1000 == 0:\n",
    "    #    val_acc_lst.append(val_acc(SimSiamNet(model, net)))\n",
    "    if epoch % 10 == 0:\n",
    "        print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
    "        running_loss = 0.0\n",
    "        \n",
    "print(val_acc(SimSiamNet(model, net)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f730d21a-395b-43d0-8302-d5e63ea0cfc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1696e90c-3fd8-49f7-88b6-5190c3867953",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac49020-7c09-4e85-84bf-50c745d99dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ace36d9-319d-480c-9892-23a25133c031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123d4d72-5c78-45df-af8b-45f3c0303b38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28686330-13b1-4b78-9d2d-5acee8f6a9eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98804eb0-2d15-4dcd-b738-0781d4729d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06d78fb1-5a28-41fa-acf3-f62b273316ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "PytorchStreamReader failed reading zip archive: failed finding central directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3790/2201359202.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         simsiam.resnet18.resnet18(), 2048, 512)\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nets/simsiam_resnet18_v2.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data_sup/X_250.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    598\u001b[0m             \u001b[0;31m# reset back to the original position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[0morig_position\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m_is_torchscript_zip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m                     warnings.warn(\"'torch.load' received a zip file that looks like a TorchScript archive\"\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name_or_buffer)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyTorchFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: PytorchStreamReader failed reading zip archive: failed finding central directory"
     ]
    }
   ],
   "source": [
    "model_names = sorted(name for name in models.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "    and callable(models.__dict__[name]))\n",
    "device = torch.device('cuda') \n",
    "model = simsiam.builder_resnet18_2.SimSiam(\n",
    "        simsiam.resnet18.resnet18(), 2048, 512)\n",
    "\n",
    "model.load_state_dict(torch.load('nets/simsiam_resnet18_v2.pt'))\n",
    "\n",
    "images = torch.load('data_sup/X_250.pt')\n",
    "labels = torch.load('data_sup/y_250.pt')\n",
    "\n",
    "im = []\n",
    "lab = []\n",
    "\n",
    "model.to(device)\n",
    "\"\"\"\n",
    "for i in range(int(len(images)/4)):\n",
    "    input_ = torch.cat((images[i].cuda(), images[i+1].cuda(), images[i+2].cuda(), images[i+3].cuda()), 0)\n",
    "    im.append(model.forward_lat_pool(input_).detach())\n",
    "    lab.append(torch.cat((labels[i].cuda(), labels[i+1].cuda(), labels[i+2].cuda(), labels[i+3].cuda()), 0))\n",
    "    #input_ = torch.cat((images[i], images[i+1], images[i+2], images[i+3]), 0)\n",
    "    #im.append(model.forward_lat_pool(input_).detach())\n",
    "    #lab.append(torch.cat((labels[i], labels[i+1], labels[i+2], labels[i+3]), 0))\n",
    "   \"\"\" \n",
    "normalize = transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                                     std=[0.2023, 0.1994, 0.2010])\n",
    "augmentation = [\n",
    "    transforms.RandomResizedCrop(28, scale=(0.2, 1.)),\n",
    "    transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.RandomApply([simsiam.loader.GaussianBlur([.1, 2.])], p=0.5),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "    ]\n",
    "data_storage = \"./data\"\n",
    "trainset = torchvision.datasets.CIFAR10(root=data_storage, train=True,\n",
    "                                        download=True, transform=simsiam.loader.TwoCropsTransform(transforms.Compose(augmentation)))\n",
    "#trainset = torch.utils.data.Subset(trainset, range(0, 40, 1))\n",
    "    \n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size = 8, shuffle= True,\n",
    "        num_workers=4, pin_memory=True, drop_last=True)\n",
    "\n",
    "\n",
    "im1 = []\n",
    "lab1 = []\n",
    "\n",
    "for images1, labels1 in train_loader:\n",
    "    input_ = images1[0].cuda()\n",
    "    im1.append(model.forward_lat_pool(input_).detach())\n",
    "    lab1.append(labels1.cuda())\n",
    "    #print(input_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06e9984e-b7e6-40b9-8efd-8b426bb567b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'im1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3790/1628976843.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# loop over the dataset multiple times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;31m# get the inputs; data is a list of [inputs, labels]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlab1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'im1' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# NOTERA ATT Net() måste ha samma input dim som model har output dim. \n",
    "class SimSiamNet:\n",
    "    def __init__(self, model1, model2):\n",
    "        super().__init__()\n",
    "        self.simsiam = model1\n",
    "        self.classifier = model2\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.simsiam.forward_lat_pool(x).detach()\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.CenterCrop(28),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "def val_acc(simsiam_net):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        times = 0\n",
    "        for data in testloader:\n",
    "            times += 1\n",
    "            images, labels = data\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = simsiam_net.forward(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            if times == 50:\n",
    "                break\n",
    "    return correct / total\n",
    "\n",
    "net = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.02, weight_decay=0.000001, momentum=0.9)\n",
    "\n",
    "val_acc_lst = []\n",
    "net.to(device)\n",
    "for epoch in range(50000):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i in range(len(im1)):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = im1[i], lab1[i]\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        #print(f\"Pred: {outputs[0].argmax()}, Label: {labels[0]}\")\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    if epoch % 1000 == 0:\n",
    "        val_acc_lst.append(val_acc(SimSiamNet(model, net)))\n",
    "    if epoch % 1000 == 0:\n",
    "        print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
    "        running_loss = 0.0\n",
    "        \n",
    "plt.plot(val_acc_lst)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec3f51b-aeb6-4f5c-91e6-bb7285096053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9130893-5f63-49fe-a49b-69690c183a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-9.m82",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m82"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
